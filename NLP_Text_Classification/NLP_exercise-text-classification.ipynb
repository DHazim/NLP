{"cells":[{"metadata":{},"cell_type":"markdown","source":["**This notebook is an exercise in the [Natural Language Processing](https://www.kaggle.com/learn/natural-language-processing) course.  You can reference the tutorial at [this link](https://www.kaggle.com/matleonard/text-classification).**\n","\n","---\n"]},{"metadata":{},"cell_type":"markdown","source":["# Natural Language Classification\n","\n","The manager wants to create a tool that automatically sends him all the negative reviews so he can fix them, while automatically sending all the positive reviews to the owner, so the manager can ask for a raise. \n","\n","We will first build a model to distinguish positive reviews from negative reviews using Yelp reviews because these reviews include a rating with each review. Your data consists of the text body of each review along with the star rating. Ratings with 1-2 stars count as \"negative\", and ratings with 4-5 stars are \"positive\". Ratings with 3 stars are \"neutral\" and have been dropped from the data.\n","\n","Let's get started."]},{"metadata":{"trusted":true},"cell_type":"code","source":["import pandas as pd\n"],"execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Step 1: Evaluate the Approach\n","\n","The strength of this approach is that it allows you to distinguish positive email messages from negative emails even though you don't have historical emails that you have labeled as positive or negative.\n","\n","The weakness of this approach is that emails may be systematically different from Yelp reviews in ways that make your model less accurate. For example, customers might generally use different words or slang in emails, and the model based on Yelp reviews won't have seen these words.\n","\n","If we want to see how serious this issue is, we could compare word frequencies between the two sources. In practice, manually reading a few emails from each source may be enough to see if it's a serious issue.\n","\n","If we want to do something fancier, we can create a dataset that contains both Yelp reviews and emails and see whether a model can tell a reviews source from the text content. Ideally, we'd like to find that model didn't perform well, because it would mean your data sources are similar. That approach seems unnecessarily complex here."]},{"metadata":{},"cell_type":"markdown","source":["# Step 2: Review Data and Create the model\n","\n","Moving forward with the plan, we'll need to load the data. load data and split it into a training and validation set."]},{"metadata":{"trusted":true},"cell_type":"code","source":["def load_data(csv_file, split=0.9):\n","    data = pd.read_csv(csv_file)\n","    \n","    # Shuffle data\n","    train_data = data.sample(frac=1, random_state=7)\n","    \n","    texts = train_data.text.values\n","    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n","              for y in train_data.sentiment.values]\n","    split = int(len(train_data) * split)\n","    \n","    train_labels = [{\"cats\": labels} for labels in labels[:split]]\n","    val_labels = [{\"cats\": labels} for labels in labels[split:]]\n","    \n","    return texts[:split], train_labels, texts[split:], val_labels\n","\n","train_texts, train_labels, val_texts, val_labels = load_data('../Text_classification/yelp_ratings.csv')"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}]},{"metadata":{},"cell_type":"markdown","source":["we will use this training data to build a model."]},{"metadata":{"trusted":true},"cell_type":"code","source":["print('Texts from training data\\n------')\n","print(train_texts[:2])\n","print('\\nLabels from training data\\n------')\n","print(train_labels[:2])\n"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Texts from training data\n------\n[\"Some of the best sushi I've ever had....and I come from the East Coast.  Unreal toro, have some of it's available.\"\n \"One of the best burgers I've ever had and very well priced. I got the tortilla burger and is was delicious especially with there tortilla soup!\"]\n\nLabels from training data\n------\n[{'cats': {'POSITIVE': True, 'NEGATIVE': False}}, {'cats': {'POSITIVE': True, 'NEGATIVE': False}}]\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":["import spacy\n","\n","# Create an empty model\n","nlp = spacy.blank(\"en\")\n","\n","# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n","config={\"model\":{\"@architectures\" : \"spacy.TextCatBOW.v1\",\n","\"exclusive_classes\" : True,\n","\"ngram_size\" : 1,\n","\"no_output_layer\" :False},}\n","\n","# config={\"exclusive_classes\": True, \"architecture\": \"bow\"}\n","\n","textcat = nlp.add_pipe(\"textcat\", config=config)\n","\n","\n","# Add NEGATIVE and POSITIVE labels to text classifier\n","textcat.add_label(\"NEGATIVE\")\n","textcat.add_label(\"POSITIVE\")\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":16}]},{"metadata":{},"cell_type":"markdown","source":["# Step 3: Train Function\n","\n","Let's implement a function `train` that updates a model with training data. Most of this is general data munging."]},{"metadata":{"trusted":false},"cell_type":"code","source":["from spacy.util import minibatch\n","from spacy.training import Example\n","import random\n","\n","def train(model, train_data, optimizer):\n","    losses = {}\n","    random.seed(1)\n","    random.shuffle(train_data)\n","    \n","    batches = minibatch(train_data, size=8)\n","    for batch in batches:\n","        # train_data is a list of tuples [(text0, label0), (text1, label1), ...]\n","        # Split batch into texts and labels\n","        examples= [Example.from_dict(nlp(text), cat) for text, cat in batch]\n","        \n","        # Update model with texts and labels\n","        model.update(examples, sgd=optimizer, losses=losses, drop=0.2)\n","        \n","    return losses\n"],"execution_count":21,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["# Fix seed for reproducibility\n","spacy.util.fix_random_seed(1)\n","random.seed(1)\n","\n","# This may take a while to run!\n","optimizer = nlp.begin_training()\n","train_data = list(zip(train_texts, train_labels))\n","losses = train(nlp, train_data, optimizer)\n","print(losses['textcat'])"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["8.227033224776854\n"]}]},{"metadata":{},"cell_type":"markdown","source":["We can try this slightly trained model on some example text and look at the probabilities assigned to each label."]},{"metadata":{"trusted":false},"cell_type":"code","source":["text = \"This tea cup was full of holes. Do not recommend.\"\n","doc = nlp(text)\n","print(doc.cats)"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'NEGATIVE': 0.6776847839355469, 'POSITIVE': 0.32231518626213074}\n"]}]},{"metadata":{},"cell_type":"markdown","source":["These probabilities look reasonable. Now we should turn them into an actual prediction.\n","\n","# Step 4: Making Predictions\n","\n","Let's implement a function `predict` that predicts the sentiment of text examples. \n","- First, tokenize the texts using `nlp.tokenizer()`. \n","- Then, pass those docs to the TextCategorizer which we can get from `nlp.get_pipe()`. \n","- Use the `textcat.predict()` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."]},{"metadata":{"trusted":false},"cell_type":"code","source":["def predict(nlp, texts): \n","    # Use the model's tokenizer to tokenize each input text\n","    docs = [nlp(text) for text in texts]\n","    \n","    # Use textcat to get the scores for each doc\n","    scores = textcat.predict(docs)\n","    \n","    # From the scores, find the class with the highest score/probability\n","    predicted_class = scores.argmax(axis=1)\n","    \n","    return predicted_class"],"execution_count":29,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["texts = val_texts[34:38]\n","predictions = predict(nlp, texts)\n","\n","for p, t in zip(predictions, texts):\n","    print(f\"{textcat.labels[p]}: {t} \\n\")"],"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["POSITIVE: Came over and had their \"Pick 2\" lunch combo and chose their best selling 1/2 chicken sandwich with quinoa.  Both were tasty, the chicken salad is a bit creamy but was perfect with quinoa on the side.  This is a good lunch joint, casual and clean! \n\nPOSITIVE: Went here last night and got oysters, fried okra, fries, and onion rings. I cannot complain. The portions were great and tasty!!! I will definitely be back for more. I cannot wait to try the crawfish boudin and soft shell crab. \n\nPOSITIVE: This restaurant was fantastic! \nThe concept of eating without vision was intriguing. The dinner was filled with laughs and good conversation. \n\nWe were lead in a line to our table and each person to their seat. This was not just dark but you could not see something right in front of your face. \n\nThe waiters/waitresses were all blind and allowed us to see how aware you need to be without the vision. \n\nTaking away one sense is said to increase your other senses so as taste and hearing which I believed to be true in this experience. \n\nThe meal was extremely delicious. I had the chicken and it was cooked to perfection. I also had a surprise beer which was a nice surprise. \n\nThe whole experience was unlike anything I have ever done and I hope this spreads to other cities. \n\nA must do! \n\nNEGATIVE: They won't book new patients for same day appointments. My dog is sick but it's not necessarily urgent so I asked when I would be able to book an appointment and was told \"new patients book out at least 6 weeks in advance\" so just a heads up this seems like a great vet from other reviews but it'll be hard to get in their system to know \n\n"]}]},{"metadata":{},"cell_type":"markdown","source":["# Step 5: Evaluate The Model\n","\n","Let's implement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, which is the number of correct predictions divided by all predictions.\n","\n","First, we use the `predict` method to get the predicted class for each text in `texts`, then, we find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."]},{"metadata":{"trusted":false},"cell_type":"code","source":["def evaluate(model, texts, labels):\n","    \"\"\" Returns the accuracy of a TextCategorizer model. \n","    \n","        Arguments\n","        ---------\n","        model: ScaPy model with a TextCategorizer\n","        texts: Text samples, from load_data function\n","        labels: True labels, from load_data function\n","    \n","    \"\"\"\n","    # Get predictions from textcat model (using your predict method)\n","    predicted_class = predict(model, texts)\n","    \n","    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n","    true_class = [int(each['cats']['POSITIVE']) for each in labels]\n","    \n","    # A boolean or int array indicating correct predictions\n","    correct_predictions = predicted_class == true_class\n","    \n","    # The accuracy, number of correct predictions divided by all predictions\n","    accuracy = correct_predictions.mean()\n","    \n","    return accuracy"],"execution_count":31,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":["accuracy = evaluate(nlp, val_texts, val_labels)\n","print(f\"Accuracy: {accuracy:.4f}\")"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9448\n"]}]},{"metadata":{},"cell_type":"markdown","source":["With the functions implemented, you can train and evaluate in a loop."]},{"source":["# This may take a while to run!\n","n_iters = 5\n","for i in range(n_iters):\n","    losses = train(nlp, train_data, optimizer)\n","    accuracy = evaluate(nlp, val_texts, val_labels)\n","    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")"],"cell_type":"code","metadata":{"trusted":false},"execution_count":null,"outputs":[{"output_type":"error","ename":"Error","evalue":"Pip module Unable to parse debugpy output, please log an issue with https://github.com/microsoft/vscode-jupyter is required for debugging cells. You will need to install it to debug cells.","traceback":["Error: Pip module Unable to parse debugpy output, please log an issue with https://github.com/microsoft/vscode-jupyter is required for debugging cells. You will need to install it to debug cells.","at b.parseConnectInfo (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:49:486311)","at b.connectToLocal (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:49:486838)","at async b.connect (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:49:484715)","at async b.startDebugSession (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:49:483862)","at async f.submitCode (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:32:585464)","at async f.handleRunByLine (c:\\Users\\MEHDI\\.vscode\\extensions\\ms-toolsai.jupyter-2020.12.414227025\\out\\client\\extension.js:9:173871)"]}]},{"metadata":{},"cell_type":"markdown","source":["# Step 6: Ideas for improvements\n","\n","There are various hyperparameters to work with here. The biggest one is the TextCategorizer architecture. You used the simplest model which trains faster but likely has worse performance than the CNN and ensemble models.\n"]},{"source":[],"cell_type":"markdown","metadata":{"trusted":false}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.8.3-final","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}